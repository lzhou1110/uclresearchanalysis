{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/uclresearchanalysis\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Reading config file from location: '\n",
      " '/home/ec2-user/uclresearchanalysis/configuration/env.properties')\n",
      "{'calculate': {'analysis': True,\n",
      "               'friends': True,\n",
      "               'network': True,\n",
      "               'uniquetweets': True,\n",
      "               'uniqueusers': True},\n",
      " 'data': {'dates': ['2017-12-10', '2017-12-11', '2017-12-12'],\n",
      "          'eventname': 'nyc attack',\n",
      "          'phrases': ['nyc%20explosion',\n",
      "                      'nyc%20bombing',\n",
      "                      'nyc%20attack',\n",
      "                      'nyc%20terror',\n",
      "                      'new%20york%20explosion',\n",
      "                      'new%20york%20bombing',\n",
      "                      'new%20york%20attack',\n",
      "                      'new%20york%20terror',\n",
      "                      'manhattan%20explosion',\n",
      "                      'manhattan%20bombing',\n",
      "                      'manhattan%20attack',\n",
      "                      'manhattan%20terror',\n",
      "                      'port%20authority%20explosion',\n",
      "                      'port%20authority%20bombing',\n",
      "                      'port%20authority%20attack',\n",
      "                      'port%20authority%20terror'],\n",
      "          'starttime': 'Dec 11 07:00:00 -0500 2017'},\n",
      " 'path': {'cwd': '/home/ec2-user/uclresearchanalysis/data/nyc',\n",
      "          'ml': '/home/ec2-user/uclresearchanalysis/data/nyc/pickle',\n",
      "          'networkx': {'all': '/home/ec2-user/uclresearchanalysis/data/nyc/pickle/networkx_all.dat',\n",
      "                       'friends': '/home/ec2-user/uclresearchanalysis/data/nyc/pickle/networkx_friends.dat',\n",
      "                       'potential': '/home/ec2-user/uclresearchanalysis/data/nyc/pickle/networkx_potential.dat'},\n",
      "          'newcrawl': '/home/ec2-user/uclresearchanalysis/other/newcrawl.dat',\n",
      "          'other': '/home/ec2-user/uclresearchanalysis/other',\n",
      "          'pickle': {'friends': '/home/ec2-user/uclresearchanalysis/data/nyc/pickle/friends.dat',\n",
      "                     'needcrawl': '/home/ec2-user/uclresearchanalysis/data/nyc/pickle/needcrawl.dat',\n",
      "                     'network': '/home/ec2-user/uclresearchanalysis/data/nyc/pickle/network.dat',\n",
      "                     'tweets': '/home/ec2-user/uclresearchanalysis/data/nyc/pickle/tweets.dat',\n",
      "                     'users': '/home/ec2-user/uclresearchanalysis/data/nyc/pickle/users.dat'},\n",
      "          'result': '/home/ec2-user/uclresearchanalysis/data/nyc/result',\n",
      "          'twitter': '/home/ec2-user/uclresearchanalysis/data/nyc/twitter'},\n",
      " 'save_to_file': 'False',\n",
      " 'timeframe': '1440'}\n"
     ]
    }
   ],
   "source": [
    "import builtins\n",
    "# builtins.uclresearch_topic = 'GIVENCHY'\n",
    "# builtins.uclresearch_topic = 'HAWKING'\n",
    "builtins.uclresearch_topic = 'NYC'\n",
    "# builtins.uclresearch_topic = 'FLORIDA'\n",
    "from configuration import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "import datetime as dt\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterApi(object):\n",
    "    def __init__(self, consumer_key, consumer_secret, access_token, access_secret): \n",
    "        self.consumer_key = consumer_key \n",
    "        self.consumer_secret = consumer_secret \n",
    "        self.access_token = access_token\n",
    "        self.access_secret = access_secret\n",
    "\n",
    "    def loadapi(self):\n",
    "        auth = OAuthHandler(self.consumer_key, self.consumer_secret)\n",
    "        auth.set_access_token(self.access_token, self.access_secret)\n",
    "        return tweepy.API(\n",
    "            auth, \n",
    "            wait_on_rate_limit=True, \n",
    "            wait_on_rate_limit_notify=True, \n",
    "            compression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_friendship(thread_name, api, user_id):\n",
    "    follower_ids = []\n",
    "    try:\n",
    "        c = tweepy.Cursor(api.friends_ids, id = user_id)\n",
    "        for page in c.pages():\n",
    "            follower_ids.extend(page)\n",
    "    except tweepy.TweepError as e:\n",
    "        print('tweepy.TweepError', e, ' from: ', thread_name)\n",
    "    except:\n",
    "        e = sys.exc_info()[0]\n",
    "        print(\"Error: {}, from: {}\".format(e, thread_name))  \n",
    "    return follower_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_friendship(thread_name, friendship_dictionary):\n",
    "    filename = 'newcrawl-{date:%Y-%m-%d %H:%M:%S}-{}.dat'.format(\n",
    "        thread_name, \n",
    "        date=datetime.datetime.now())\n",
    "    config.dump_newcrawl_dictionary(friendship_dictionary, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class crwalThread(threading.Thread):\n",
    "    def __init__(self, thread_id, thread_name, api, user_ids):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.thread_id = thread_id\n",
    "        self.thread_name = thread_name\n",
    "        self.api = api\n",
    "        self.user_ids = user_ids\n",
    "    def run(self):\n",
    "        print('{}: {}'.format(self.thread_name, ': starting'))\n",
    "        dump_dictionary_if_over_this_size = 5\n",
    "        friends_dictionary = {}\n",
    "        while len(self.user_ids) > 0:\n",
    "            user_id = self.user_ids.pop()\n",
    "            friends_dictionary[user_id] = crawl_friendship(self.thread_name, self.api, user_id)\n",
    "            if len(friends_dictionary.keys()) >= dump_dictionary_if_over_this_size:\n",
    "                save_friendship(self.thread_name, friends_dictionary)\n",
    "                friends_dictionary = {}\n",
    "        save_friendship(self.thread_name, friends_dictionary)\n",
    "        print('{}: {}'.format(self.thread_name, ': exiting'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39 apis, could crawl 56160 friendships per day\n",
      "Loading data file from path /home/ec2-user/uclresearchanalysis/data/nyc/pickle/needcrawl.dat\n",
      "'Loaded 81859 entires'\n",
      "Number of users we still need to crawl: 81859\n",
      "Jimmy_Canteen: : starting\n",
      "BarberDdddavid: : starting\n",
      "Hu13Steve: : starting\n",
      "james13_david: : starting\n",
      "hui: : starting\n",
      "lzhoudevuk: : starting\n",
      "lzhoudevcn: : starting\n",
      "lzhoudevau: : starting\n",
      "ucablz4: : starting\n",
      "liyi.zhou.17: : starting\n",
      "lzhou1110: : starting\n",
      "wu: : starting\n",
      "peter.liyi.z: : starting\n",
      "miao: : starting\n",
      "adlrl: : starting\n",
      "adlrl: : starting\n",
      "åˆ‘: : starting\n",
      "tao: : starting\n",
      "tao: : starting\n",
      "May: : starting\n",
      "wangliming: : starting\n",
      "RqYdi3lOQAPy48M:ZC7L83aIzyCJ:+380689865832: : starting\n",
      "t8Ftv93xbP5Xx31:55DrMrMClYDcC:+380631829691: : starting\n",
      "FnhaYcFHgRxMvk9:QR1VMXntTTmI:+380631829678: : starting\n",
      "OnQODRg0SvtVEsR:watn3EhnLDuW:+77079113127: : starting\n",
      "0inWj5RtO5gZd46:3NRevYJvKywXA:+79771231636: : startingB6Q5h589vf6dxC8:O6yzku47a027:+380631752188: : starting\n",
      "\n",
      "2CR2CpMfAjbg5i6:4NPsTWh5h9ke:+79877421998: : starting\n",
      "07gdL1BhO2wrmBL:JNTZrF0avxEkA:+79168086647: : starting\n",
      "l7fvRd5gPyj5uQN:nRHWDp2Mq9cW:+77711526518: : starting\n",
      "qUokZmCoGUFbzea:rh0wzk2OVEGP:+77054930224: : starting\n",
      "v5HnCE59uzquXFR:ZIaC6BEOa2DMx:+79870425016: : starting\n",
      "0WsUWLQgfVaAjIz:2tK0eEyi2uiuq:+380689866267: : starting\n",
      "KhwqLBN7yQC0vlo:5L2NWd37w3pw:+77472138036: : starting\n",
      "m1JkL69lsTWLdRc:YM6nY0U0JfzG:+79775803296: : starting\n",
      "4bgDWT1jrHyGVac:wLYy4cE9tBde:+380689648361: : starting\n",
      "QCbLLso1w4WIege:sP1v0xb2GDil:+79103981850: : starting\n",
      "lwPjbu9DRW9Hefy:4CvJUQTxdZUji:+380631751859: : starting\n",
      "z16kJviE55ydmQ7:0bxqAwbHO5l59:+380960729679: : starting\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for:Rate limit reached. Sleeping for: 847\n",
      " 847\n",
      "Rate limit reached. Sleeping for:Rate limit reached. Sleeping for: 847\n",
      " 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: Rate limit reached. Sleeping for: 847\n",
      "847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for:Rate limit reached. Sleeping for: 847\n",
      " 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: Rate limit reached. Sleeping for:Rate limit reached. Sleeping for: 847\n",
      "847\n",
      " Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for:847\n",
      " 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for: 847\n",
      "Rate limit reached. Sleeping for:Rate limit reached. Sleeping for: 847\n",
      " 847\n",
      "Rate limit reached. Sleeping for: 847\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e52cc062c7c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach_thread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0meach_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished crawling\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keys = config.load_twitter_keys()\n",
    "number_of_apis = len(keys.index)\n",
    "print('Found {} apis, could crawl {} friendships per day'.format(keys.shape[0], keys.shape[0] * 60 * 24))\n",
    "need_to_crawl = list(config.load_needcrawl_set())\n",
    "print('Number of users we still need to crawl: {}'.format(len(need_to_crawl)))\n",
    "splitted_user_ids = list(split(need_to_crawl, keys.shape[0]))\n",
    "\n",
    "threads = []\n",
    "for index, row in keys.iterrows():    \n",
    "    twitterApi = TwitterApi(row.consumer_key, row.consumer_secret, row.access_token, row.access_secret).loadapi()\n",
    "    threads.append(crwalThread(index, row.reference, twitterApi, splitted_user_ids[0]))\n",
    "\n",
    "for each_thread in threads:\n",
    "    each_thread.start()    \n",
    "    \n",
    "for each_thread in threads:\n",
    "    each_thread.join()\n",
    "    \n",
    "print(\"Finished crawling\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
