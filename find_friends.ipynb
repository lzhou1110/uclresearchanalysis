{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "import datetime as dt\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'calculate': {'analysis': True,\n",
      "               'friends': False,\n",
      "               'network': True,\n",
      "               'uniquetweets': True,\n",
      "               'uniqueusers': True},\n",
      " 'data': {'dates': ['2017-12-10', '2017-12-11', '2017-12-12'],\n",
      "          'eventname': 'nyc attack',\n",
      "          'phrases': ['nyc%20explosion',\n",
      "                      'nyc%20bombing',\n",
      "                      'nyc%20attack',\n",
      "                      'nyc%20terror',\n",
      "                      'new%20york%20explosion',\n",
      "                      'new%20york%20bombing',\n",
      "                      'new%20york%20attack',\n",
      "                      'new%20york%20terror',\n",
      "                      'manhattan%20explosion',\n",
      "                      'manhattan%20bombing',\n",
      "                      'manhattan%20attack',\n",
      "                      'manhattan%20terror',\n",
      "                      'port%20authority%20explosion',\n",
      "                      'port%20authority%20bombing',\n",
      "                      'port%20authority%20attack',\n",
      "                      'port%20authority%20terror'],\n",
      "          'starttime': 'Dec 11 07:00:00 -0500 2017'},\n",
      " 'path': {'cwd': '/Users/lzhou/git/github/uclresearchanalysis/data/nyc',\n",
      "          'newcrawl': '/Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat',\n",
      "          'pickle': {'friends': '/Users/lzhou/git/github/uclresearchanalysis/data/nyc/pickle/friends.dat',\n",
      "                     'needcrawl': '/Users/lzhou/git/github/uclresearchanalysis/data/nyc/pickle/needcrawl.dat',\n",
      "                     'network': '/Users/lzhou/git/github/uclresearchanalysis/data/nyc/pickle/network.dat',\n",
      "                     'tweets': '/Users/lzhou/git/github/uclresearchanalysis/data/nyc/pickle/tweets.dat',\n",
      "                     'users': '/Users/lzhou/git/github/uclresearchanalysis/data/nyc/pickle/users.dat'},\n",
      "          'result': '/Users/lzhou/git/github/uclresearchanalysis/data/nyc/result',\n",
      "          'twitter': '/Users/lzhou/git/github/uclresearchanalysis/data/nyc/twitter'},\n",
      " 'timeframe': '1440'}\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "from config import load_needcrawl_set\n",
    "from config import load_newcrawl_dictionary\n",
    "from config import dump_newcrawl_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterApi(object):\n",
    "    def __init__(self, consumer_key, consumer_secret, access_token, access_secret): \n",
    "        self.consumer_key = consumer_key \n",
    "        self.consumer_secret = consumer_secret \n",
    "        self.access_token = access_token\n",
    "        self.access_secret = access_secret\n",
    "\n",
    "    def loadapi(self):\n",
    "        auth = OAuthHandler(self.consumer_key, self.consumer_secret)\n",
    "        auth.set_access_token(self.access_token, self.access_secret)\n",
    "        return tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True)\n",
    "\n",
    "twitter_api_list = []\n",
    "# Jimmy Canteen 0\n",
    "twitter_api_list.append(TwitterApi(\n",
    "    'ogd44qNt9NHukPsUsnKmn1Wm3', \n",
    "    'g0PMron4C0eOD7NYpSqekzUwPwRafUpYTOKgiAabA5fkpS2a4l', \n",
    "    '936587907007176704-2xAvOIe5u5FTkuAanmWLJRkwKlMPqnD',\n",
    "    'DTJQl1JjQdbVErGlTGBI7g7wyHeWt8o0eQZJIb4fewn3J'\n",
    ").loadapi())\n",
    "# BarberDdddavid 1\n",
    "twitter_api_list.append(TwitterApi(\n",
    "    'Imk26gt1YacAmZqsBvwXNNZp1', \n",
    "    'ZTVGMr0B6e8PLaFWFtQFbBSta4e0E3POjZO0Ps4uU7XX2jp08c', \n",
    "    '948501581372280832-2Ux6iejRB0Mr7KOyQ2psV5hgN8rCvAW',\n",
    "    'cwCusThG5QGtLoLusElVWdMKtZ8VHvJmngBGjqCkpO77S'\n",
    ").loadapi())\n",
    "# Hu13Steve 2\n",
    "twitter_api_list.append(TwitterApi(\n",
    "    'Lqz4r2UGJ3MALpX7TygEWkdvu', \n",
    "    '4irrPlKdKpqdo35PAlqx1g7oTLXL79KGh8ul0Ug3NP7NPnJ5fq', \n",
    "    '948494955756052481-HBHi8eC43VnafcgKj1hfQrkiQgdazld',\n",
    "    '1hfPh52QxAWtku4AqNnjUytGCWyt4AkNllR0RGdNag5wW'\n",
    ").loadapi())\n",
    "# james13_david 3\n",
    "twitter_api_list.append(TwitterApi(\n",
    "    'QweR1meYNPziTVMQfnPBw7u7L', \n",
    "    'w2imXsR0TKSqafgZP0LU1spudls7SnCcUqskUUubmvmstbah5S', \n",
    "    '940722476585312257-i94glXYrPQa4LYqhLz75qNfaDHXrFpU',\n",
    "    'xezy1i3SKqkiVVBHy25avg1pybkfuR1CIbUzRGj5mq6Mo'\n",
    ").loadapi())\n",
    "# hui's crawler 4\n",
    "twitter_api_list.append(TwitterApi(\n",
    "    'FImHy1gMljimQMQxG6432rATE', \n",
    "    '8oNc5WX3srEophN8oiGrnBeta1iX1QWPM9IDl3scyuzitHZkTp', \n",
    "    '1976839820-bH0EOOIuJQC5yqZRDv5iJo8Gpp3Uerz76OOug99',\n",
    "    'ntdfl0pjZZYVHsLTDK1wKiEsKHS5B9mAdvyCDhREQqDzG'\n",
    ").loadapi())\n",
    "# lzhoudevuk 5 \n",
    "twitter_api_list.append(TwitterApi(\n",
    "    'MP1ydHbs9wSPCvUO0HcJlBd1s', \n",
    "    'yeVQtGsq4pgYrX6tBqMtKcscrGULJE9SCPyP38vFDaAhUtSJiw', \n",
    "    '959980110588899329-A943y5m9XFhivFJXXw0N1uRSdesdYlY',\n",
    "    'hP63SwoueduNQSSe4pwlZNhegjJCXVn4qjeZPfv762KsJ'\n",
    ").loadapi())\n",
    "# lzhoudevcn 6 \n",
    "twitter_api_list.append(TwitterApi(\n",
    "    'cM2Ket4JdIrFCoFJfZR6dKEJW', \n",
    "    'VzewbPMeZcIu8aakQ0cnOmhPnJmHhazFDG9cCSgka01JqT463a', \n",
    "    '959978501125402624-iRPiJiSVy7TDihEf1HsV74Ow72iavWO',\n",
    "    'ZvInw0gQb8xRvMLwoG6PDy18JwM66vhhyFnskeisZBGRe'\n",
    ").loadapi())\n",
    "# lzhoudevau passed 7 \n",
    "twitter_api_list.append(TwitterApi(\n",
    "    'pbFZlAThsyleV4IWazYaG6WH0', \n",
    "    'w01obwo4ECZfl4aIbhEA8q5GnMGTKVXiWvsDq6D8eE4DiwTpps', \n",
    "    '959974918619385856-sGUbwHJQd8YrdoNkJGDTyvpafFjh7wi',\n",
    "    '676MhvwxiPZoUv6f8Upm2fVaZiPUa5jDvCwFHA05HowiE'\n",
    ").loadapi())\n",
    "# ucablz4 passed 8\n",
    "twitter_api_list.append(TwitterApi(\n",
    "    'CeIvDs3UbPO4Yj4XK6ZFHzVIU', \n",
    "    'j0eRROwvGFk1CEciSehtUOc2SCVmxzMhWbQd3sUDhztdICPtMW', \n",
    "    '930982504596672517-AE7R6i4xaNPUeXME2S4cyeTgSJNBVEv',\n",
    "    'JEmF4hPSTD65lFmYM1Zm3x4I6Xf7kUQ93NvlodJ2jPrQN'\n",
    ").loadapi())\n",
    "# liyi.zhou.17 passed 9\n",
    "twitter_api_list.append(TwitterApi(\n",
    "    'AdCVM7NUpICq9RcYnZiM68FLb', \n",
    "    '0hbBfyXK8CBCvl9S6Zu1CkWTlAo1c4rvfsAl8ot4VPehTLpHL4', \n",
    "    '930982019672178689-UpCYlSLDFDiwcr44weBZoDO4CY2npyE',\n",
    "    's3Z5H1cADAMYElfGhYCE27ZQSWNR4EP2n1FcJmcwG80ZB'\n",
    ").loadapi())\n",
    "# lzhou1110 10\n",
    "twitter_api_list.append(TwitterApi(\n",
    "    'yom0HoCImxDZobnZzDrJsESke',\n",
    "    'iPDqeGyq40FbovpFUoLdunLnFINEDB5MQuzFFbo0KBoBiM4mk0',\n",
    "    '910787059501150208-vvOcHytvhGncJTtuAF23tywLu5UTSbL',\n",
    "    'lL4vIlZlKMurhhgsZGM11hGh6LG6cUBtaHqbMiLYJTZhj'\n",
    ").loadapi())\n",
    "# tao 11\n",
    "twitter_api_list.append(TwitterApi(\n",
    "    'YZD91p9NpWydELrliHkx3FkV2',\n",
    "    'dchHYkpVxp7Uq1Mi5fA94GfCKWFUrQ1VRp0kQJsI2nXXTJjqUk',\n",
    "    '960929372206223360-TgkpvCQWqTdf9Po9DaOJCrOCGHiMGVV',\n",
    "    'pRCYaoy3cKWmzvIZ3rDExlxSBI1SVTVIGLRfvpzFxTaVp'\n",
    ").loadapi())\n",
    "# wu api 12\n",
    "twitter_api_list.append(TwitterApi(\n",
    "    '6hDKNKAEVflvc1QiKWRwEvqIU',\n",
    "    'LAOoZL1qKs4l9VTyWRKOibLj4tm14n6ZziMX9wd9Wo3NJ8ADyC',\n",
    "    '961193810951856129-nGfaxWcrgS4i0gReDmyg68xOZoWiBPU',\n",
    "    'xDwZpIXjrvcUZpqxz39e77XM924Ek9tBQ69aC9JtDPMEC'\n",
    ").loadapi())\n",
    "# peter.liyi.z api 13\n",
    "twitter_api_list.append(TwitterApi(\n",
    "    'AFRdbq1jpYv5uHzc2XXilJBMY',\n",
    "    'UvSj6ZnbUG0t3nQASgd7kSHeiCoL14Iadt4f8gI4Y4QhsanovG',\n",
    "    '2166615014-QcdbmCt252E02I2wAMVgXAJMXtE5tgyQpABuAkr',\n",
    "    '5nYYyhO1WenLXLuuQ6Kthlg8xOg7wlcX7zEP1aLg6abHT'\n",
    ").loadapi())\n",
    "# miao api 14\n",
    "twitter_api_list.append(TwitterApi(\n",
    "    'FlmshcUW970JhOuWCrffznTzM',\n",
    "    '33oh92E47FaeQm6GNWvC5axvmN3nRm6IKhKwN7UX7Xys7pfCtA',\n",
    "    '320714154-woEAipLwLvVwkJo2o9i5IYvoSaFGqzV6pN8nTboL',\n",
    "    'M0UVpBAPdGI3yzfXqXd7vhcx4DRttCLV9LsQTjRR7Fpei'\n",
    ").loadapi())\n",
    "# ucl lzhou adlrl account 15\n",
    "twitter_api_list.append(TwitterApi(\n",
    "    '45mvtiqyyq5B1cXi6kPJHq2TO',\n",
    "    'yrCn2qyWiyYNZXgGX0RhHCAUFV0pjg30twa9txtwltX2CYJvRy',\n",
    "    '961358756595535873-obN8fa0WJRG7y5ptgtEbO0btCXWagwx',\n",
    "    'hCKeIKCThs1xmCUsiaMms0jkHXNshVHSVTu1hbUcTa1kz'\n",
    ").loadapi())\n",
    "# ucl lzhou adlrl account ucablz4 16\n",
    "twitter_api_list.append(TwitterApi(\n",
    "    '75xtkzO360GjmMgLhaSZ1zH0u',\n",
    "    '2QM0T8J3Jwy4aJEuaTJk9GT6PxkcFVpGqgwoqWvmkvgvq7mqdr',\n",
    "    '961359707809157122-EUhutRfRHEBPSeE791pVGzYd2oMMq87',\n",
    "    'WrgrnvyxVNBFNtkDwD4e1sGw2rQNhvbiOU9YaGkgcK1jA'\n",
    ").loadapi())\n",
    "# 浙大 刑 17\n",
    "twitter_api_list.append(TwitterApi(\n",
    "    'T5cDUb70emiXsUqIInL9cDo8v',\n",
    "    'mrdtfmZdaHI0c7C1i07F6YOs6Pvwg2br6P3KJ6jAFnXFJOAuYd',\n",
    "    '811130947982626816-LFaMFVl0nH51VP8Ug6PdythywNGs1V1',\n",
    "    '9NsemWbHwhH0KhERWGJyKIXZ7ws4iEqKiIMLjJA2VoPlO'\n",
    ").loadapi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data file from path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "'Loaded 119 entires'\n",
      "Loading data file from path /Users/lzhou/git/github/uclresearchanalysis/data/nyc/pickle/needcrawl.dat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0.00/140k [00:00<?, ?Twitter friendship/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Loaded 143639 entires'\n",
      "Number of users we still need to crawl: 143520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18.0/140k [00:05<11:31:24, 3.46Twitter friendship/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping data to path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "('Finished dumping data to path '\n",
      " '/Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat')\n",
      "Loading data file from path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "'Loaded 137 entires'\n",
      "tweepy.TweepError Not authorized.  from:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 36.0/140k [00:09<11:08:10, 3.58Twitter friendship/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping data to path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "('Finished dumping data to path '\n",
      " '/Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat')\n",
      "Loading data file from path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "'Loaded 155 entires'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 54.0/140k [00:13<10:23:39, 3.83Twitter friendship/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping data to path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "('Finished dumping data to path '\n",
      " '/Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat')\n",
      "Loading data file from path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "'Loaded 173 entires'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 72.0/140k [00:17<10:05:51, 3.95Twitter friendship/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping data to path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "('Finished dumping data to path '\n",
      " '/Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat')\n",
      "Loading data file from path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "'Loaded 191 entires'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 90.0/140k [00:21<9:40:35, 4.12Twitter friendship/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping data to path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "('Finished dumping data to path '\n",
      " '/Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat')\n",
      "Loading data file from path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "'Loaded 209 entires'\n",
      "tweepy.TweepError Not authorized.  from:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 108/140k [00:25<9:22:46, 4.25Twitter friendship/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping data to path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "('Finished dumping data to path '\n",
      " '/Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat')\n",
      "Loading data file from path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "'Loaded 227 entires'\n",
      "tweepy.TweepError Not authorized.  from:  10\n",
      "tweepy.TweepError Not authorized.  from:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 126/140k [00:29<9:10:42, 4.34Twitter friendship/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweepy.TweepError Not authorized.  from:  17\n",
      "Dumping data to path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "('Finished dumping data to path '\n",
      " '/Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat')\n",
      "Loading data file from path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "'Loaded 245 entires'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 144/140k [00:33<9:00:36, 4.42Twitter friendship/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping data to path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "('Finished dumping data to path '\n",
      " '/Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat')\n",
      "Loading data file from path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "'Loaded 263 entires'\n",
      "tweepy.TweepError Not authorized.  from:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 162/140k [00:38<9:25:14, 4.23Twitter friendship/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweepy.TweepError [{'code': 34, 'message': 'Sorry, that page does not exist.'}]  from:  17\n",
      "Dumping data to path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "('Finished dumping data to path '\n",
      " '/Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat')\n",
      "Loading data file from path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "'Loaded 281 entires'\n",
      "tweepy.TweepError [{'code': 34, 'message': 'Sorry, that page does not exist.'}]  from:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 180/140k [00:42<9:17:23, 4.29Twitter friendship/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping data to path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "('Finished dumping data to path '\n",
      " '/Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat')\n",
      "Loading data file from path /Users/lzhou/git/github/uclresearchanalysis/other/newcrawl.dat\n",
      "'Loaded 299 entires'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 858\n"
     ]
    }
   ],
   "source": [
    "def tweet_find_friends(api, user_id, logger):\n",
    "    follower_ids = []\n",
    "    try:\n",
    "        c = tweepy.Cursor(api.friends_ids, id = user_id)\n",
    "        for page in c.pages():\n",
    "            follower_ids.extend(page)\n",
    "    except tweepy.TweepError as e:\n",
    "        print('tweepy.TweepError', e, ' from: ', logger)\n",
    "    except:\n",
    "        e = sys.exc_info()[0]\n",
    "        print(\"Error: %s\" % e)  \n",
    "    return follower_ids\n",
    "        \n",
    "def crawl_twitter_friend(api, friends_dictionary, user_id, logger):\n",
    "    friends_dictionary[user_id] = tweet_find_friends(api, user_id, logger)\n",
    "\n",
    "    \n",
    "try:\n",
    "    friends_dictionary = load_newcrawl_dictionary()\n",
    "except:\n",
    "    friends_dictionary = {}\n",
    "    \n",
    "need_to_crawl = list(load_needcrawl_set() - friends_dictionary.keys())\n",
    "\n",
    "print('Number of users we still need to crawl: {}'.format(len(need_to_crawl)))\n",
    "api_counter = 0\n",
    "number_of_apis = len(twitter_api_list)\n",
    "with tqdm(total = len(need_to_crawl), unit='Twitter friendship', unit_scale=True, unit_divisor=1024) as pbar:\n",
    "    while len(need_to_crawl) != 0:\n",
    "        for api_counter in range(min(len(need_to_crawl), number_of_apis)):\n",
    "            user_id = need_to_crawl.pop()\n",
    "            crawl_twitter_friend(twitter_api_list[api_counter], friends_dictionary, user_id, api_counter)\n",
    "        pbar.update(number_of_apis)\n",
    "        dump_newcrawl_dictionary(friends_dictionary)\n",
    "        friends_dictionary = load_newcrawl_dictionary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
